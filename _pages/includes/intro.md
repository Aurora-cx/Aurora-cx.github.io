<span class='anchor' id='about-me'></span>
<div style="line-height: 1.5;">

Hi! I'm Chenxi Wang (Aurora), a second-year M.Sc. student in NLP at MBZUAI, supervised by [Prof. Xiuying Chen](https://iriscxy.github.io/). Prior to MBZUAI, I got my B.Eng. degree in Computer Science at Xi'an Jiaotong University.

My research focuses on uncovering the latent capabilities of large language models (LLMs). These models encode far richer knowledge and behaviors than they naturally express under normal inference. I take an **interpretability-first post-training** approach to **awaken** these latent capabilities and make them reliably available on demand. Using interpretability techniques such as circuit discovery and control, I localize and modulate the internal mechanisms that give rise to specific behaviors. This enables controlled, inference-time activation of these capabilities **without additional large-scale pretraining**, paving the way for more adaptive and efficient model behaviors.

<mark style="background-color: #FFE4E1; padding: 2px 4px;">ðŸŒŸ My current work explores <strong>AI that meets human emotional needs</strong>, building explainable, controllable, and personalized emotional-support systems that can evolve with user needs.</mark>

I welcome thoughtful discussions on dependency risk, and I'm happy to chat about philosophy of mind and what makes AI feel more human :)

<p style="color: #FF6B35; font-weight: bold;">Actively seeking PhD positions for Fall 2026. Please see my CV and feel free to get in touch.</p>

</div>

