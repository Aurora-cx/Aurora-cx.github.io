<span class='anchor' id='about-me'></span>

Hi! I’m Chenxi Wang (Aurora), a second-year M.Sc. student in NLP at MBZUAI, supervised by [Prof. Xiuying Chen](https://iriscxy.github.io/). I earned my B.Eng. in Computer Science from Xi’an Jiaotong University, where my undergraduate thesis ranked first in my cohort.

My research focuses on human-centered AI. I take an **interpretability-first post-training** approach to **awaken** latent knowledge and behaviors in pretrained LLMs that are not actively invoked under normal inference. I use interpretability techniques including circuit discovery and control, subspace analysis, steering vectors, activation patching, and sparse autoencoders. I aim to surface the capabilities users want and express them controllably at inference, without additional large-scale pretraining.

My current work targets **intelligence that meets human emotional needs**, building explainable, controllable, and personalized emotional-support AI that can evolve with user needs. I am also open to thoughtful discussions about dependency risk. (Also open to casual chats about philosophy of mind and what makes AI feel more human.)



